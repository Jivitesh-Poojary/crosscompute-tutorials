{
 "metadata": {
  "name": "401 Harness machine learning with Scikit-Learn"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal is to build a machine that make decisions automatically\n",
      "using information it has not seen before, and whose performance\n",
      "improves with experience. The approach in machine learning is to \n",
      "develop algorithms that make decisions using a model fitted on data.\n",
      "\n",
      "# Machine learning is easy with Scikit-Learn\n",
      "The scikit-learn package is a collection of machine learning algorithms\n",
      "that share a common usage pattern:\n",
      "\n",
      "- Load data.\n",
      "- Pick model.\n",
      "- Fit model parameters to data.\n",
      "- Predict using fitted model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets, neighbors\n",
      "iris = datasets.load_iris()\n",
      "model = neighbors.KNeighborsClassifier()\n",
      "model.fit(iris.data, iris.target)\n",
      "model.predict([7.5, 3, 6.5, 2.1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [Scikit-Learn Tutorials](http://scikit-learn.org/dev)\n",
      "- [Scikit-Learn Examples](http://scikit-learn.org/dev/auto_examples)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take a moment to browse the official tutorials and examples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Which model do we use?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "trainingSet = X[:-100], y[:-100]\n",
      "testSet = X[-100:], y[-100:]\n",
      "\n",
      "def evaluate_model(model):\n",
      "    return model.fit(*trainingSet).score(*testSet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.gaussian_process import GaussianProcess\n",
      "evaluate_model(GaussianProcess())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "evaluate_model(DecisionTreeClassifier())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "evaluate_model(SVC(kernel='linear', C=0.001))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluate model performance with [cross-validation](http://scikit-learn.org/dev/model_selection.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "iris = load_iris()\n",
      "model = LogisticRegression()\n",
      "cross_val_score(model, iris.data, iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(model, iris.data, iris.target, cv=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import LeaveOneOut\n",
      "\n",
      "cross_val_score(model, iris.data, iris.target, cv=LeaveOneOut(len(iris.target)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluate stack performance with [pipelining](http://scikit-learn.org/dev/modules/pipeline.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.lib.display import YouTubeVideo\n",
      "YouTubeVideo('1uS5b8aQ6z8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.datasets import load_digits; digits = load_digits()\n",
      "\n",
      "model = Pipeline([\n",
      "    ('pca', PCA()), \n",
      "    ('logistic', LogisticRegression()),\n",
      "])\n",
      "np.mean(cross_val_score(model, digits.data, digits.target))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## [Transform](http://scikit-learn.org/dev/data_transforms.html) data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "model = Pipeline([\n",
      "    ('scaler', StandardScaler()),\n",
      "    ('pca', PCA()), \n",
      "    ('logistic', LogisticRegression()),\n",
      "])\n",
      "np.mean(cross_val_score(model, digits.data, digits.target))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's vectorize a stanza from Zbigniew Herbert's [A Knocker](http://www.poemhunter.com/poem/a-knocker/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "vectorizer = CountVectorizer(min_df=1)\n",
      "documents = [\n",
      "    'my imagination',\n",
      "    'is a piece of board',\n",
      "    'my sole instrument',\n",
      "    'is a wooden stick',\n",
      "]\n",
      "X = vectorizer.fit_transform(documents)\n",
      "documentVectors = X.toarray()\n",
      "documentVectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featureNames = vectorizer.get_feature_names()\n",
      "for bagOfWords in documentVectors:\n",
      "    print zip(featureNames, bagOfWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Optimize model parameters systematically with [Grid Search](http://scikit-learn.org/dev/modules/grid_search.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adapted from \n",
      "# http://scikit-learn.org/dev/tutorial/statistical_inference/putting_together.html\n",
      "from sklearn import linear_model, decomposition, datasets\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('pca', decomposition.PCA()), \n",
      "    ('logistic', linear_model.LogisticRegression()),\n",
      "])\n",
      "gridSearch = GridSearchCV(pipeline, dict(\n",
      "    pca__n_components=[20, 40],\n",
      "    logistic__C=[1, 1000]))\n",
      "\n",
      "digits = datasets.load_digits()\n",
      "gridSearch.fit(digits.data, digits.target)\n",
      "valueByParameter = gridSearch.best_estimator_.get_params()\n",
      "for parameter in gridSearch.param_grid:\n",
      "    print '%s: %r' % (parameter, valueByParameter[parameter])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Identify a translator of Zbigniew Herbert"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from archiveIO import Archive, TemporaryFolder\n",
      "\n",
      "archive = Archive('datasets/ZbigniewHerbert.tar.gz')\n",
      "documents = []\n",
      "categories = []\n",
      "with TemporaryFolder() as temporaryFolder:\n",
      "    for documentPath in archive.load(temporaryFolder):\n",
      "        text = open(documentPath).read()\n",
      "        documents.append(text)\n",
      "        categories.append('Carpenter' in text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', SGDClassifier()),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {\n",
      "    'vect__max_df': (0.5, 0.75, 1.0),\n",
      "    'vect__max_n': (1, 2),\n",
      "    'clf__alpha': (0.00001, 0.000001),\n",
      "    'clf__penalty': ('l2', 'elasticnet'),\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "gridSearch = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
      "gridSearch.fit(documents, categories)\n",
      "\n",
      "valueByParameter = gridSearch.best_estimator_.get_params()\n",
      "for parameter in gridSearch.param_grid:\n",
      "    print '%s: %r' % (parameter, valueByParameter[parameter])\n",
      "print \"Best score: %0.3f\" % gridSearch.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print documents[27]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [Scikit-Learn Documentation](http://scikit-learn.org/dev/)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}