{
 "metadata": {
  "name": "491 Prototype GPU computation techniques with PyCUDA"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [PyCUDA](http://mathema.tician.de/software/pycuda)\n",
      "- [PyCUDA code repository](https://github.com/inducer/pycuda)\n",
      "- [PyCUDA code examples](https://github.com/inducer/pycuda/tree/master/examples)\n",
      "- [PyCUDA code tests](https://github.com/inducer/pycuda/tree/master/test)\n",
      "- [PyCUDA videos](http://pyvideo.org/search?models=videos.video&q=pycuda)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from pycuda import autoinit, driver as cuda, gpuarray\n",
      "from pycuda.compiler import SourceModule\n",
      "from pycuda.elementwise import ElementwiseKernel\n",
      "from pycuda.reduction import ReductionKernel\n",
      "\n",
      "vectorHost = np.array(xrange(256)).astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "device = autoinit.device\n",
      "print 'GPU Name: {}'.format(device.name())\n",
      "print 'GPU Memory: {:,}'.format(device.total_memory())\n",
      "print '\\n'.join('{}: {:,}'.format(key, value) for key, value in device.get_attributes().iteritems())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Define computation\n",
      "\n",
      "Define computation directly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Send vector to device\n",
      "vectorDevice = gpuarray.to_gpu(vectorHost)\n",
      "# Get result from device\n",
      "(2 * vectorDevice).get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get result from device\n",
      "(gpuarray.dot(vectorDevice, vectorDevice)).get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define computation with ElementwiseKernel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare kernel\n",
      "kernel = ElementwiseKernel(\n",
      "    'float *vector',\n",
      "    'vector[i] *= 2')\n",
      "# Send vector to device\n",
      "vectorHost = np.array(xrange(256)).astype(np.float32)\n",
      "vectorDevice = gpuarray.to_gpu(vectorHost)\n",
      "# Get result from device\n",
      "kernel(vectorDevice)\n",
      "vectorHost = vectorDevice.get()\n",
      "print vectorHost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define computation with SourceModule."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare kernel\n",
      "kernel = SourceModule(\"\"\"\n",
      "    __global__ void doublify(float *vector) {\n",
      "        vector[threadIdx.x] *= 2;\n",
      "    }\n",
      "\"\"\").get_function('doublify')\n",
      "# Compute\n",
      "vectorHost = np.array(xrange(256)).astype(np.float32)\n",
      "kernel(cuda.InOut(vectorHost), block=(vectorHost.size, 1, 1))\n",
      "print vectorHost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare kernel\n",
      "kernel = SourceModule(\"\"\"\n",
      "    __global__ void doublify(float *vector) {{\n",
      "        vector[threadIdx.x] *= {scalar};\n",
      "    }}\n",
      "\"\"\".format(scalar=2)).get_function('doublify')\n",
      "# Compute\n",
      "vectorHost = np.array(xrange(256)).astype(np.float32)\n",
      "kernel(cuda.InOut(vectorHost), block=(vectorHost.size, 1, 1))\n",
      "print vectorHost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare kernel\n",
      "kernel = SourceModule(\"\"\"\n",
      "    __global__ void doublify(float *vector) {\n",
      "        int offset = threadIdx.x + threadIdx.y * blockDim.x;\n",
      "        vector[offset] *= 2;\n",
      "    }\n",
      "\"\"\").get_function('doublify')\n",
      "# Compute\n",
      "vectorHost = np.array([[1, 2], [3, 4]]).astype(np.float32)\n",
      "kernel(cuda.InOut(vectorHost), block=(\n",
      "    vectorHost.shape[0], \n",
      "    vectorHost.shape[1], \n",
      "    1,\n",
      "))\n",
      "print vectorHost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define operation with ReductionKernel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare kernel\n",
      "kernel = ReductionKernel(\n",
      "    np.float32,                     # Precision for input and output\n",
      "    neutral='0',                    # Starting value for reduction\n",
      "    map_expr='x[i] * y[i]',         # C code defining map()\n",
      "    reduce_expr='a + b',            # C code defining reduce()\n",
      "    arguments='float *x, float *y') # Function arguments\n",
      "# Send vector to device\n",
      "vectorHost = np.array(xrange(256)).astype(np.float32)\n",
      "vectorDevice = gpuarray.to_gpu(vectorHost)\n",
      "# Get result from device\n",
      "resultHost = kernel(vectorDevice, vectorDevice).get()\n",
      "print resultHost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Time computation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Send vector to device\n",
      "vectorHost = np.array(xrange(256)).astype(np.float32)\n",
      "vectorDevice = gpuarray.to_gpu(vectorHost)\n",
      "\n",
      "# Start timer\n",
      "start = cuda.Event()\n",
      "end = cuda.Event()\n",
      "start.record()\n",
      "\n",
      "# Get result from device\n",
      "vectorHost = (2 * vectorDevice).get()\n",
      "\n",
      "# End timer\n",
      "end.record()\n",
      "end.synchronize()\n",
      "print '{:,} seconds'.format(start.time_till(end) * 1e-3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}